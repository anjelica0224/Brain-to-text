{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":106809,"databundleVersionId":13056355,"sourceType":"competition"}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!ls -R /kaggle/input/brain-to-text-25\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-30T11:46:01.007899Z","iopub.execute_input":"2025-11-30T11:46:01.008124Z","iopub.status.idle":"2025-11-30T11:46:01.429200Z","shell.execute_reply.started":"2025-11-30T11:46:01.008102Z","shell.execute_reply":"2025-11-30T11:46:01.428403Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"/kaggle/input/brain-to-text-25:\ndata_link.txt  t15_copyTask_neuralData\tt15_pretrained_rnn_baseline\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData:\nhdf5_data_final\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final:\nt15.2023.08.11\tt15.2023.09.29\tt15.2023.11.04\tt15.2024.02.25\tt15.2024.07.19\nt15.2023.08.13\tt15.2023.10.01\tt15.2023.11.17\tt15.2024.03.03\tt15.2024.07.21\nt15.2023.08.18\tt15.2023.10.06\tt15.2023.11.19\tt15.2024.03.08\tt15.2024.07.28\nt15.2023.08.20\tt15.2023.10.08\tt15.2023.11.26\tt15.2024.03.15\tt15.2025.01.10\nt15.2023.08.25\tt15.2023.10.13\tt15.2023.12.03\tt15.2024.03.17\tt15.2025.01.12\nt15.2023.08.27\tt15.2023.10.15\tt15.2023.12.08\tt15.2024.04.25\tt15.2025.03.14\nt15.2023.09.01\tt15.2023.10.20\tt15.2023.12.10\tt15.2024.04.28\tt15.2025.03.16\nt15.2023.09.03\tt15.2023.10.22\tt15.2023.12.17\tt15.2024.05.10\tt15.2025.03.30\nt15.2023.09.24\tt15.2023.11.03\tt15.2023.12.29\tt15.2024.06.14\tt15.2025.04.13\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.11:\ndata_train.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.13:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.18:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.20:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.25:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.27:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.09.01:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.09.03:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.09.24:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.09.29:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.01:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.06:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.08:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.13:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.15:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.20:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.22:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.03:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.04:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.17:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.19:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.26:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.03:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.08:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.10:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.17:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.29:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.02.25:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.03.03:\ndata_train.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.03.08:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.03.15:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.03.17:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.04.25:\ndata_train.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.04.28:\ndata_train.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.05.10:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.06.14:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.07.19:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.07.21:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.07.28:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.01.10:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.01.12:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.03.14:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.03.16:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.03.30:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.04.13:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_pretrained_rnn_baseline:\nt15_pretrained_rnn_baseline\n\n/kaggle/input/brain-to-text-25/t15_pretrained_rnn_baseline/t15_pretrained_rnn_baseline:\ncheckpoint  training_log\n\n/kaggle/input/brain-to-text-25/t15_pretrained_rnn_baseline/t15_pretrained_rnn_baseline/checkpoint:\nargs.yaml  best_checkpoint\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import h5py\n\nsample = \"/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.01.12/data_train.hdf5\"\nwith h5py.File(sample, \"r\") as f:\n    first_trial = list(f.keys())[0]\n    print(\"Example trial:\", first_trial)\n    print(\"Contents:\")\n    for key in f[first_trial].keys():\n        print(\"  \", key)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T11:46:01.431319Z","iopub.execute_input":"2025-11-30T11:46:01.431664Z","iopub.status.idle":"2025-11-30T11:46:01.679089Z","shell.execute_reply.started":"2025-11-30T11:46:01.431631Z","shell.execute_reply":"2025-11-30T11:46:01.678493Z"}},"outputs":[{"name":"stdout","text":"Example trial: trial_0000\nContents:\n   input_features\n   seq_class_ids\n   transcription\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"train_h5 = \"/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.01.12/data_train.hdf5\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T11:46:01.679853Z","iopub.execute_input":"2025-11-30T11:46:01.680256Z","iopub.status.idle":"2025-11-30T11:46:01.683670Z","shell.execute_reply.started":"2025-11-30T11:46:01.680237Z","shell.execute_reply":"2025-11-30T11:46:01.683036Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Extract all label IDs from train set to infer vocabulary\nall_ids = set()\n\nwith h5py.File(train_h5, \"r\") as f:\n    for k in list(f.keys())[:200]:   # first 200 trials are enough\n        ids = f[f\"{k}/seq_class_ids\"][:]\n        all_ids.update(ids.tolist())\n\nprint(\"Unique token IDs:\", sorted(all_ids))\nprint(\"Count:\", len(all_ids))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T11:46:01.684424Z","iopub.execute_input":"2025-11-30T11:46:01.685023Z","iopub.status.idle":"2025-11-30T11:46:02.424815Z","shell.execute_reply.started":"2025-11-30T11:46:01.685005Z","shell.execute_reply":"2025-11-30T11:46:02.424062Z"}},"outputs":[{"name":"stdout","text":"Unique token IDs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\nCount: 41\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import h5py, numpy as np, torch, torch.nn as nn, torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport math, random\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", DEVICE)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T11:46:02.425702Z","iopub.execute_input":"2025-11-30T11:46:02.426119Z","iopub.status.idle":"2025-11-30T11:46:06.063340Z","shell.execute_reply.started":"2025-11-30T11:46:02.426098Z","shell.execute_reply":"2025-11-30T11:46:06.062225Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# ASCII printable characters + mandatory blank at index 0\nchars = ['<blank>'] + [chr(i) for i in range(32,127)]\nstoi = {c:i for i,c in enumerate(chars)}\nitos = {i:c for c,i in stoi.items()}\nVOCAB_SIZE = len(stoi)\n\ndef ascii_to_tokens(arr):\n    # Converts raw ascii ints → model token ids\n    out=[]\n    for x in arr:\n        if x == 0: \n            continue\n        c = chr(int(x))\n        if c in stoi:\n            out.append(stoi[c])\n    return torch.tensor(out, dtype=torch.long)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T11:46:06.064079Z","iopub.execute_input":"2025-11-30T11:46:06.064513Z","iopub.status.idle":"2025-11-30T11:46:06.075479Z","shell.execute_reply.started":"2025-11-30T11:46:06.064481Z","shell.execute_reply":"2025-11-30T11:46:06.072412Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class Brain2TextDataset(Dataset):\n    def __init__(self, h5_path, max_trials=None):\n        self.f = h5py.File(h5_path, \"r\")\n        keys = list(self.f.keys())\n\n        # Keep only trials that contain *at least one* label source\n        self.valid_keys = []\n        for k in keys:\n            grp = self.f[k]\n            if \"transcription\" in grp or \"seq_class_ids\" in grp:\n                self.valid_keys.append(k)\n\n        if max_trials is not None:\n            self.valid_keys = self.valid_keys[:max_trials]\n\n    def __len__(self):\n        return len(self.valid_keys)\n\n    def __getitem__(self, idx):\n        k = self.valid_keys[idx]\n        grp = self.f[k]\n\n        # Neural data\n        x = grp[\"input_features\"][()]  # (T, 512)\n\n        # Labels: use transcription first, else fallback\n        if \"transcription\" in grp:\n            y_raw = grp[\"transcription\"][()]  # ASCII ints\n            y = ascii_to_tokens(y_raw)\n\n        else:\n            # seq_class_ids are already integers (but may include 0 padding)\n            y_raw = grp[\"seq_class_ids\"][()]\n            y = torch.tensor([t for t in y_raw if t != 0], dtype=torch.long)\n\n        return torch.tensor(x, dtype=torch.float32), y\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T11:46:06.078926Z","iopub.execute_input":"2025-11-30T11:46:06.079458Z","iopub.status.idle":"2025-11-30T11:46:06.093460Z","shell.execute_reply.started":"2025-11-30T11:46:06.079431Z","shell.execute_reply":"2025-11-30T11:46:06.092487Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def ctc_collate(batch):\n    xs, ys = zip(*batch)  # lists of tensors\n    x_lens = torch.tensor([len(x) for x in xs], dtype=torch.long)\n    y_lens = torch.tensor([len(y) for y in ys], dtype=torch.long)\n\n    X = nn.utils.rnn.pad_sequence(xs, batch_first=True)\n    Y = torch.cat(ys)\n\n    return X, Y, x_lens, y_lens\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T11:46:06.094434Z","iopub.execute_input":"2025-11-30T11:46:06.094726Z","iopub.status.idle":"2025-11-30T11:46:06.110562Z","shell.execute_reply.started":"2025-11-30T11:46:06.094693Z","shell.execute_reply":"2025-11-30T11:46:06.109603Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"train_h5 = \"/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.01.12/data_train.hdf5\"\nval_h5   = \"/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.01.12/data_val.hdf5\"\ntest_h5  = \"/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.01.12/data_test.hdf5\"\n\ntrain_ds = Brain2TextDataset(train_h5, max_trials=800)   # adjust subset size\nval_ds   = Brain2TextDataset(val_h5, max_trials=200)\ntest_ds  = Brain2TextDataset(test_h5, max_trials=200)\n\ntrain_dl = DataLoader(train_ds, batch_size=8, shuffle=True, collate_fn=ctc_collate)\nval_dl   = DataLoader(val_ds, batch_size=8, shuffle=False, collate_fn=ctc_collate)\ntest_dl  = DataLoader(test_ds, batch_size=8, shuffle=False, collate_fn=ctc_collate)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T11:46:06.111594Z","iopub.execute_input":"2025-11-30T11:46:06.112041Z","iopub.status.idle":"2025-11-30T11:46:06.771972Z","shell.execute_reply.started":"2025-11-30T11:46:06.112017Z","shell.execute_reply":"2025-11-30T11:46:06.771407Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass ResidualGRU(nn.Module):\n    def __init__(self, feat_dim, hidden=256, layers=4, dropout=0.15):\n        super().__init__()\n        self.layers = nn.ModuleList()\n        self.projections = nn.ModuleList()\n\n        for _ in range(layers):\n            gru = nn.GRU(\n                input_size=feat_dim,\n                hidden_size=hidden,\n                num_layers=1,\n                batch_first=True,\n                bidirectional=True\n            )\n            self.layers.append(gru)\n\n            # project from (hidden*2) → feat_dim so residual matches\n            self.projections.append(nn.Linear(hidden * 2, feat_dim))\n\n        self.dropout = dropout\n\n        self.conv = nn.Conv1d(feat_dim, feat_dim, kernel_size=5, padding=2)\n\n\n    def forward(self, x, xl):\n        for gru, proj in zip(self.layers, self.projections):\n            packed = nn.utils.rnn.pack_padded_sequence(x, xl.cpu(), batch_first=True, enforce_sorted=False)\n            out, _ = gru(packed)\n            out, _ = nn.utils.rnn.pad_packed_sequence(out, batch_first=True)\n            out = proj(out)\n            x = x + F.dropout(out, p=self.dropout, training=self.training)\n        return x, xl\n\n\nclass BrainRNN(nn.Module):\n    def __init__(self, feat_dim, vocab):\n        super().__init__()\n        self.rnn = ResidualGRU(feat_dim, hidden=256, layers=4, dropout=0.1)\n        self.fc = nn.Linear(feat_dim, vocab)\n\n    def forward(self, x, xl):\n        out, xl = self.rnn(x, xl)\n        logits = self.fc(out)\n        logp = F.log_softmax(logits, dim=-1)\n        return logp, xl\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T11:46:06.772715Z","iopub.execute_input":"2025-11-30T11:46:06.772959Z","iopub.status.idle":"2025-11-30T11:46:06.782460Z","shell.execute_reply.started":"2025-11-30T11:46:06.772933Z","shell.execute_reply":"2025-11-30T11:46:06.781845Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"sample_X, _, _, _ = next(iter(train_dl))\nFEAT_DIM = sample_X.shape[-1]\nprint(\"Feature dimension:\", FEAT_DIM)\n\nmodel = BrainRNN(FEAT_DIM, VOCAB_SIZE).to(DEVICE)\noptimizer = torch.optim.AdamW(model.parameters(), lr=4e-4, weight_decay=1e-3)\nctc_loss = nn.CTCLoss(blank=0, zero_infinity=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T11:46:06.783094Z","iopub.execute_input":"2025-11-30T11:46:06.783423Z","iopub.status.idle":"2025-11-30T11:46:09.759447Z","shell.execute_reply.started":"2025-11-30T11:46:06.783401Z","shell.execute_reply":"2025-11-30T11:46:09.758869Z"}},"outputs":[{"name":"stdout","text":"Feature dimension: 512\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"def train_step(dataloader):\n    model.train()\n    total_loss = 0\n\n    for X, Y, x_lens, y_lens in dataloader:\n        X = X.to(DEVICE)\n        Y = Y.to(DEVICE)\n        x_lens = x_lens.to(DEVICE)\n        y_lens = y_lens.to(DEVICE)\n\n        optimizer.zero_grad()\n\n        # Forward pass\n        logp, out_lens = model(X, x_lens)\n\n        # CTC expects (T, B, C)\n        logp = logp.transpose(0, 1)\n\n        loss = ctc_loss(logp, Y, out_lens, y_lens)\n        loss.backward()\n\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    return total_loss / len(dataloader)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T11:46:09.760141Z","iopub.execute_input":"2025-11-30T11:46:09.760559Z","iopub.status.idle":"2025-11-30T11:46:09.766140Z","shell.execute_reply.started":"2025-11-30T11:46:09.760534Z","shell.execute_reply":"2025-11-30T11:46:09.765303Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def greedy_decode(logp, lens):\n    # logp: (B, T, vocab)\n    pred = logp.argmax(dim=-1)  # (B, T)\n    output = []\n\n    for i in range(pred.size(0)):\n        seq = pred[i][:lens[i]].tolist()\n        # collapse repeats + remove blanks (0)\n        cleaned = []\n        last = None\n        for x in seq:\n            if x != last and x != 0:\n                cleaned.append(x)\n            last = x\n        output.append(cleaned)\n    return output\n\n\ndef validate(dataloader):\n    model.eval()\n    total_wer = 0\n    count = 0\n\n    with torch.no_grad():\n        for X, Y, x_lens, y_lens in dataloader:\n            X = X.to(DEVICE)\n            Y = Y.to(DEVICE)\n            x_lens = x_lens.to(DEVICE)\n            y_lens = y_lens.to(DEVICE)\n\n            logp, out_lens = model(X, x_lens)\n\n            preds = greedy_decode(logp.cpu(), out_lens.cpu())\n\n            # split targets by lengths\n            idx = 0\n            targets = []\n            for L in y_lens:\n                targets.append(Y[idx:idx+L].tolist())\n                idx += L\n\n            # compute a VERY rough WER (edit distance / target length)\n            for p, t in zip(preds, targets):\n                if len(t) == 0:\n                    continue\n                dist = edit_distance(p, t)\n                total_wer += dist / len(t)\n                count += 1\n\n    return total_wer / max(1, count)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T11:46:09.767096Z","iopub.execute_input":"2025-11-30T11:46:09.767389Z","iopub.status.idle":"2025-11-30T11:46:09.790183Z","shell.execute_reply.started":"2025-11-30T11:46:09.767350Z","shell.execute_reply":"2025-11-30T11:46:09.789673Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def edit_distance(a, b):\n    dp = [[0]*(len(b)+1) for _ in range(len(a)+1)]\n\n    for i in range(len(a)+1):\n        dp[i][0] = i\n    for j in range(len(b)+1):\n        dp[0][j] = j\n\n    for i in range(1, len(a)+1):\n        for j in range(1, len(b)+1):\n            cost = 0 if a[i-1] == b[j-1] else 1\n            dp[i][j] = min(\n                dp[i-1][j] + 1,\n                dp[i][j-1] + 1,\n                dp[i-1][j-1] + cost\n            )\n    return dp[-1][-1]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T11:46:09.790832Z","iopub.execute_input":"2025-11-30T11:46:09.791029Z","iopub.status.idle":"2025-11-30T11:46:09.805333Z","shell.execute_reply.started":"2025-11-30T11:46:09.791009Z","shell.execute_reply":"2025-11-30T11:46:09.804832Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"for epoch in range(1,21):\n    tr = train_step(train_dl)\n    val = validate(val_dl)\n    print(f\"Epoch {epoch:02d} | Train {tr:.3f} | Val WER {val:.3f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T11:46:09.806009Z","iopub.execute_input":"2025-11-30T11:46:09.806425Z","iopub.status.idle":"2025-11-30T11:49:12.224625Z","shell.execute_reply.started":"2025-11-30T11:46:09.806408Z","shell.execute_reply":"2025-11-30T11:49:12.223883Z"}},"outputs":[{"name":"stdout","text":"Epoch 01 | Train 36.023 | Val WER 0.813\nEpoch 02 | Train 4.606 | Val WER 0.857\nEpoch 03 | Train 4.631 | Val WER 0.869\nEpoch 04 | Train 3.603 | Val WER 0.872\nEpoch 05 | Train 3.479 | Val WER 0.854\nEpoch 06 | Train 3.300 | Val WER 0.824\nEpoch 07 | Train 3.204 | Val WER 0.886\nEpoch 08 | Train 3.067 | Val WER 0.886\nEpoch 09 | Train 2.946 | Val WER 0.863\nEpoch 10 | Train 2.821 | Val WER 0.858\nEpoch 11 | Train 2.746 | Val WER 0.878\nEpoch 12 | Train 2.618 | Val WER 0.832\nEpoch 13 | Train 2.529 | Val WER 0.822\nEpoch 14 | Train 2.394 | Val WER 0.757\nEpoch 15 | Train 2.241 | Val WER 0.770\nEpoch 16 | Train 2.072 | Val WER 0.759\nEpoch 17 | Train 1.859 | Val WER 0.756\nEpoch 18 | Train 1.612 | Val WER 0.762\nEpoch 19 | Train 1.365 | Val WER 0.772\nEpoch 20 | Train 1.118 | Val WER 0.776\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}