{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":106809,"databundleVersionId":13056355,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport h5py\nimport numpy as np\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-29T11:01:02.398250Z","iopub.execute_input":"2025-11-29T11:01:02.398488Z","iopub.status.idle":"2025-11-29T11:01:05.568011Z","shell.execute_reply.started":"2025-11-29T11:01:02.398463Z","shell.execute_reply":"2025-11-29T11:01:05.567259Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"BASE = \"/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.01.12\"\n\nTRAIN_H5 = f\"{BASE}/data_train.hdf5\"\nVAL_H5   = f\"{BASE}/data_val.hdf5\"\nTEST_H5  = f\"{BASE}/data_test.hdf5\"\n\nprint(TRAIN_H5)\nprint(VAL_H5)\nprint(TEST_H5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T11:01:05.569964Z","iopub.execute_input":"2025-11-29T11:01:05.570680Z","iopub.status.idle":"2025-11-29T11:01:05.575660Z","shell.execute_reply.started":"2025-11-29T11:01:05.570652Z","shell.execute_reply":"2025-11-29T11:01:05.574852Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.01.12/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.01.12/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.01.12/data_test.hdf5\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"class Brain2TextDataset(Dataset):\n    def __init__(self, h5_path, max_trials=None):\n        self.f = h5py.File(h5_path, \"r\")\n        self.keys = list(self.f.keys())\n\n        if max_trials is not None:\n            self.keys = self.keys[:max_trials]\n\n    def __len__(self):\n        return len(self.keys)\n\n    def __getitem__(self, idx):\n        k = self.keys[idx]\n        grp = self.f[k]\n\n        # Neural features (T, 512)\n        X = torch.tensor(grp[\"input_features\"][:], dtype=torch.float32)\n\n        # PHONEME TARGETS (seq_class_ids)\n        if \"seq_class_ids\" in grp:\n            ids = grp[\"seq_class_ids\"][:]\n            ids = [int(t) for t in ids if t != 0]  # remove padding\n            Y = torch.tensor(ids, dtype=torch.long)\n        else:\n            # fallback: transcription exists\n            text = grp[\"transcription\"][()].decode(\"utf-8\")\n            ids = [ord(c) for c in text]  # not ideal but fallback\n            Y = torch.tensor(ids, dtype=torch.long)\n\n        return X, Y\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T11:01:05.576372Z","iopub.execute_input":"2025-11-29T11:01:05.576686Z","iopub.status.idle":"2025-11-29T11:01:05.590410Z","shell.execute_reply.started":"2025-11-29T11:01:05.576661Z","shell.execute_reply":"2025-11-29T11:01:05.589497Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def ctc_collate(batch):\n    Xs, Ys = zip(*batch)\n\n    x_lens = torch.tensor([x.shape[0] for x in Xs], dtype=torch.long)\n    y_lens = torch.tensor([y.shape[0] for y in Ys], dtype=torch.long)\n\n    Xs = nn.utils.rnn.pad_sequence(Xs, batch_first=True)  # (B, T, C)\n    Ys = torch.cat(Ys)\n\n    return Xs, Ys, x_lens, y_lens\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T11:01:05.591359Z","iopub.execute_input":"2025-11-29T11:01:05.591590Z","iopub.status.idle":"2025-11-29T11:01:05.607639Z","shell.execute_reply.started":"2025-11-29T11:01:05.591570Z","shell.execute_reply":"2025-11-29T11:01:05.606930Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class ConvBiGRU(nn.Module):\n    def __init__(self, feat_dim=512, hidden=256, vocab_size=100):\n        super().__init__()\n\n        self.conv = nn.Sequential(\n            nn.Conv1d(feat_dim, feat_dim, kernel_size=5, padding=2),\n            nn.GELU(),\n        )\n\n        self.gru = nn.GRU(\n            input_size=feat_dim,\n            hidden_size=hidden,\n            num_layers=3,\n            batch_first=True,\n            bidirectional=True,\n            dropout=0.2\n        )\n\n        self.fc = nn.Linear(hidden * 2, vocab_size)\n\n    def forward(self, x, x_lens):\n        x = x.transpose(1, 2)        # (B, C, T)\n        x = self.conv(x)\n        x = x.transpose(1, 2)        # (B, T, C)\n\n        packed = nn.utils.rnn.pack_padded_sequence(\n            x, x_lens.cpu(), batch_first=True, enforce_sorted=False\n        )\n\n        out, _ = self.gru(packed)\n\n        out, out_lens = nn.utils.rnn.pad_packed_sequence(\n            out, batch_first=True\n        )\n\n        logits = self.fc(out)   # (B, T, vocab)\n        log_probs = F.log_softmax(logits, dim=-1)\n\n        log_probs = log_probs.transpose(0, 1)  # CTC expects (T, B, V)\n        return log_probs, out_lens\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T11:01:05.608388Z","iopub.execute_input":"2025-11-29T11:01:05.608627Z","iopub.status.idle":"2025-11-29T11:01:05.621008Z","shell.execute_reply.started":"2025-11-29T11:01:05.608606Z","shell.execute_reply":"2025-11-29T11:01:05.620299Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def greedy_decode_ctc(log_probs, out_lens):\n    pred_ids = log_probs.argmax(dim=-1).cpu()  # (T, B)\n\n    results = []\n    for b in range(pred_ids.size(1)):\n        seq = pred_ids[:out_lens[b], b].tolist()\n        cleaned = []\n        last = None\n        for p in seq:\n            if p != last and p != 0:   # remove repeats + blank\n                cleaned.append(p)\n            last = p\n        results.append(cleaned)\n    return results\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T11:01:05.621720Z","iopub.execute_input":"2025-11-29T11:01:05.621987Z","iopub.status.idle":"2025-11-29T11:01:05.636998Z","shell.execute_reply.started":"2025-11-29T11:01:05.621966Z","shell.execute_reply":"2025-11-29T11:01:05.636174Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def edit_distance(a, b):\n    dp = np.zeros((len(a)+1, len(b)+1), dtype=int)\n    for i in range(len(a)+1):\n        dp[i][0] = i\n    for j in range(len(b)+1):\n        dp[0][j] = j\n    for i in range(1, len(a)+1):\n        for j in range(1, len(b)+1):\n            cost = 0 if a[i-1] == b[j-1] else 1\n            dp[i][j] = min(\n                dp[i-1][j] + 1,\n                dp[i][j-1] + 1,\n                dp[i-1][j-1] + cost\n            )\n    return dp[-1][-1]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T11:01:05.638930Z","iopub.execute_input":"2025-11-29T11:01:05.639553Z","iopub.status.idle":"2025-11-29T11:01:05.649536Z","shell.execute_reply.started":"2025-11-29T11:01:05.639535Z","shell.execute_reply":"2025-11-29T11:01:05.648809Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def phoneme_error_rate(pred_seq, true_seq):\n    if len(true_seq) == 0:\n        return 0.0\n    return edit_distance(pred_seq, true_seq) / len(true_seq)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T11:01:05.650319Z","iopub.execute_input":"2025-11-29T11:01:05.650559Z","iopub.status.idle":"2025-11-29T11:01:05.662572Z","shell.execute_reply.started":"2025-11-29T11:01:05.650538Z","shell.execute_reply":"2025-11-29T11:01:05.661842Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def validate_per(dataloader):\n    model.eval()\n    total_per = 0\n    n = 0\n\n    with torch.no_grad():\n        for X, Y, x_lens, y_lens in dataloader:\n            X = X.to(device)\n            x_lens = x_lens.to(device)\n\n            logp, out_lens = model(X, x_lens)\n            preds = greedy_decode_ctc(logp.cpu(), out_lens.cpu())\n\n            idx = 0\n            targets = []\n            for L in y_lens:\n                targets.append(Y[idx:idx+L].tolist())\n                idx += L\n\n            for p, t in zip(preds, targets):\n                per = phoneme_error_rate(p, t)\n                total_per += per\n                n += 1\n\n    return total_per / n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T11:01:05.663510Z","iopub.execute_input":"2025-11-29T11:01:05.663818Z","iopub.status.idle":"2025-11-29T11:01:05.675143Z","shell.execute_reply.started":"2025-11-29T11:01:05.663791Z","shell.execute_reply":"2025-11-29T11:01:05.674412Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def train_step(dataloader):\n    model.train()\n    total_loss = 0\n\n    for X, Y, x_lens, y_lens in dataloader:\n        X = X.to(device)\n        Y = Y.to(device)\n        x_lens = x_lens.to(device)\n\n        logp, out_lens = model(X, x_lens)\n\n        loss = ctc_loss(\n            logp,\n            Y,\n            out_lens,\n            y_lens.to(device)\n        )\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    return total_loss / len(dataloader)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T11:01:05.676045Z","iopub.execute_input":"2025-11-29T11:01:05.676278Z","iopub.status.idle":"2025-11-29T11:01:05.686982Z","shell.execute_reply.started":"2025-11-29T11:01:05.676258Z","shell.execute_reply":"2025-11-29T11:01:05.686253Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class EarlyStopping:\n    def __init__(self, patience=10):\n        self.patience = patience\n        self.counter = 0\n        self.best = float(\"inf\")\n        self.should_stop = False\n\n    def step(self, metric):\n        if metric < self.best:\n            self.best = metric\n            self.counter = 0\n        else:\n            self.counter += 1\n\n        if self.counter >= self.patience:\n            self.should_stop = True\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T11:01:05.687732Z","iopub.execute_input":"2025-11-29T11:01:05.688040Z","iopub.status.idle":"2025-11-29T11:01:05.699536Z","shell.execute_reply.started":"2025-11-29T11:01:05.688010Z","shell.execute_reply":"2025-11-29T11:01:05.698710Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ntrain_ds = Brain2TextDataset(TRAIN_H5, max_trials=2000)\nval_ds   = Brain2TextDataset(VAL_H5,   max_trials=300)\n\ntrain_dl = DataLoader(train_ds, batch_size=8, shuffle=True, collate_fn=ctc_collate)\nval_dl   = DataLoader(val_ds,   batch_size=8, shuffle=False, collate_fn=ctc_collate)\n\nVOCAB_SIZE = 96  # change to your phoneme vocab size\nmodel = ConvBiGRU(feat_dim=512, hidden=256, vocab_size=VOCAB_SIZE).to(device)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\nctc_loss = nn.CTCLoss(blank=0, zero_infinity=True)\n\nearly_stop = EarlyStopping(patience=15)\n\nfor epoch in range(1, 200):\n    train_loss = train_step(train_dl)\n    val_per = validate_per(val_dl)\n\n    print(f\"Epoch {epoch:02d} | Train {train_loss:.3f} | Val PER {val_per:.3f}\")\n\n    early_stop.step(val_per)\n    if early_stop.should_stop:\n        print(\"Early stopping!\")\n        break\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T11:01:05.700318Z","iopub.execute_input":"2025-11-29T11:01:05.700566Z","iopub.status.idle":"2025-11-29T11:04:54.415517Z","shell.execute_reply.started":"2025-11-29T11:01:05.700544Z","shell.execute_reply":"2025-11-29T11:04:54.414823Z"}},"outputs":[{"name":"stdout","text":"Epoch 01 | Train 32.154 | Val PER 0.965\nEpoch 02 | Train 18.354 | Val PER 0.965\nEpoch 03 | Train 16.170 | Val PER 1.000\nEpoch 04 | Train 3.463 | Val PER 1.000\nEpoch 05 | Train 3.367 | Val PER 1.000\nEpoch 06 | Train 3.314 | Val PER 1.000\nEpoch 07 | Train 3.289 | Val PER 1.000\nEpoch 08 | Train 3.267 | Val PER 1.000\nEpoch 09 | Train 3.254 | Val PER 1.000\nEpoch 10 | Train 3.247 | Val PER 1.000\nEpoch 11 | Train 3.232 | Val PER 1.000\nEpoch 12 | Train 3.219 | Val PER 1.000\nEpoch 13 | Train 3.214 | Val PER 1.000\nEpoch 14 | Train 3.219 | Val PER 1.000\nEpoch 15 | Train 3.210 | Val PER 1.000\nEpoch 16 | Train 3.206 | Val PER 0.960\nEpoch 17 | Train 3.197 | Val PER 0.960\nEpoch 18 | Train 3.193 | Val PER 0.960\nEpoch 19 | Train 3.198 | Val PER 0.960\nEpoch 20 | Train 3.198 | Val PER 0.960\nEpoch 21 | Train 3.192 | Val PER 0.960\nEpoch 22 | Train 3.189 | Val PER 0.960\nEpoch 23 | Train 3.179 | Val PER 0.960\nEpoch 24 | Train 3.181 | Val PER 0.960\nEpoch 25 | Train 3.188 | Val PER 0.960\nEpoch 26 | Train 3.182 | Val PER 0.960\nEpoch 27 | Train 3.173 | Val PER 0.960\nEpoch 28 | Train 3.167 | Val PER 0.960\nEpoch 29 | Train 3.177 | Val PER 0.960\nEpoch 30 | Train 3.166 | Val PER 0.960\nEpoch 31 | Train 3.166 | Val PER 0.960\nEarly stopping!\n","output_type":"stream"}],"execution_count":12}]}