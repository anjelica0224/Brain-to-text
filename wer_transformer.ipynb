{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670d2d3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T14:45:14.267518Z",
     "iopub.status.busy": "2025-11-29T14:45:14.266988Z",
     "iopub.status.idle": "2025-11-29T14:45:42.163209Z",
     "shell.execute_reply": "2025-11-29T14:45:42.161854Z"
    },
    "papermill": {
     "duration": 27.934975,
     "end_time": "2025-11-29T14:45:42.164657",
     "exception": false,
     "start_time": "2025-11-29T14:45:14.229682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BRAIN-TO-TEXT WER EVALUATION\n",
      "============================================================\n",
      "\n",
      "Loading validation data...\n",
      "  data_val.hdf5: 35 trials\n",
      "  data_val.hdf5: 49 trials\n",
      "  data_val.hdf5: 48 trials\n",
      "  data_val.hdf5: 25 trials\n",
      "  data_val.hdf5: 25 trials\n",
      "  data_val.hdf5: 49 trials\n",
      "  data_val.hdf5: 34 trials\n",
      "  data_val.hdf5: 35 trials\n",
      "  data_val.hdf5: 48 trials\n",
      "  data_val.hdf5: 44 trials\n",
      "  data_val.hdf5: 36 trials\n",
      "  data_val.hdf5: 17 trials\n",
      "  data_val.hdf5: 44 trials\n",
      "  data_val.hdf5: 44 trials\n",
      "  data_val.hdf5: 9 trials\n",
      "  data_val.hdf5: 33 trials\n",
      "  data_val.hdf5: 50 trials\n",
      "  data_val.hdf5: 15 trials\n",
      "  data_val.hdf5: 25 trials\n",
      "  data_val.hdf5: 20 trials\n",
      "  data_val.hdf5: 44 trials\n",
      "  data_val.hdf5: 34 trials\n",
      "  data_val.hdf5: 50 trials\n",
      "  data_val.hdf5: 25 trials\n",
      "  data_val.hdf5: 30 trials\n",
      "  data_val.hdf5: 50 trials\n",
      "  data_val.hdf5: 23 trials\n",
      "  data_val.hdf5: 24 trials\n",
      "  data_val.hdf5: 48 trials\n",
      "  data_val.hdf5: 48 trials\n",
      "  data_val.hdf5: 25 trials\n",
      "  data_val.hdf5: 25 trials\n",
      "  data_val.hdf5: 48 trials\n",
      "  data_val.hdf5: 46 trials\n",
      "  data_val.hdf5: 48 trials\n",
      "  data_val.hdf5: 23 trials\n",
      "  data_val.hdf5: 47 trials\n",
      "  data_val.hdf5: 24 trials\n",
      "  data_val.hdf5: 24 trials\n",
      "  data_val.hdf5: 30 trials\n",
      "  data_val.hdf5: 25 trials\n",
      "\n",
      "Total trials found: 1426\n",
      "Dataset initialized with 1426 trials\n",
      "\n",
      "Loading trained model...\n",
      "✓ Model loaded from /kaggle/input/transformer/other/default/1/best_model_full_per.pt\n",
      "✓ Model has 3,301,417 parameters\n",
      "\n",
      "============================================================\n",
      "Running evaluation...\n",
      "  Processed 100/713 batches\n",
      "  Processed 200/713 batches\n",
      "  Processed 300/713 batches\n",
      "  Processed 400/713 batches\n",
      "  Processed 500/713 batches\n",
      "  Processed 600/713 batches\n",
      "  Processed 700/713 batches\n",
      "\n",
      "============================================================\n",
      "EVALUATION RESULTS\n",
      "============================================================\n",
      "Phoneme Error Rate (PER): 23.90%\n",
      "Word Error Rate (WER): 37.66%\n",
      "Total word errors: 3557\n",
      "Total words: 9445\n",
      "============================================================\n",
      "\n",
      "Sample Predictions (first 5):\n",
      "\n",
      "--- Sample 1 ---\n",
      "Pred Phonemes: Y UW  |  K AE N  |  S IY  |  DH AH  |  K UH D  |  AE T  |  DH IH S  |  P OY N T  |  AE\n",
      "True Phonemes: Y UW  |  K AE N  |  S IY  |  DH AH  |  K OW D  |  AE T  |  DH IH S  |  P OY N T  |  AE\n",
      "Pred Words: you can see the code at this point at will\n",
      "True Words: you can see the code at this point as well\n",
      "\n",
      "--- Sample 2 ---\n",
      "Pred Phonemes: HH AW  |  D AH Z  |  IH T  |  K IY P  |  DH AH  |  K AH S T  |  AE N  |   | \n",
      "True Phonemes: HH AW  |  D AH Z  |  IH T  |  K IY P  |  DH AH  |  K AA S T  |  D AW N  | \n",
      "Pred Words: how the it keep the what an\n",
      "True Words: how the it keep the cost down\n",
      "\n",
      "--- Sample 3 ---\n",
      "Pred Phonemes: N AA T  |  T UW  |  K AH N AH SH AH L  | \n",
      "True Phonemes: N AA T  |  T UW  |  K AA N T R AH V ER SH AH L  | \n",
      "Pred Words: not to <K_AH_N_AH_SH_AH_L>\n",
      "True Words: not to <K_AA_N_T_R_AH_V_ER_SH_AH_L>\n",
      "\n",
      "--- Sample 4 ---\n",
      "Pred Phonemes: DH AH  |  D T UH R IH L  |  IH N  |  AH  |  JH AH S  |  W AO K  |  T AH EH EH DH ER  | \n",
      "True Phonemes: DH AH  |  JH UH R IY  |  AH N D  |  AH  |  JH AH JH  |  W ER K  |  T AH G EH DH ER  |  AA\n",
      "Pred Words: the <D_T_UH_R_IH_L> in the the for <T_AH_EH_EH_DH_ER> in it\n",
      "True Words: the <JH_UH_R_IY> and the the will <T_AH_G_EH_DH_ER> in it\n",
      "\n",
      "--- Sample 5 ---\n",
      "Pred Phonemes: W ER  |  K W AY T  |  V OW K AH L  |  AH B AW T  |  IH T  |   |   | \n",
      "True Phonemes: W ER  |  K W AY T  |  V OW K AH L  |  AH B AW T  |  IH T  | \n",
      "Pred Words: were what <V_OW_K_AH_L> but it\n",
      "True Words: were what <V_OW_K_AH_L> but it\n",
      "\n",
      "============================================================\n",
      "FINAL RESULTS\n",
      "============================================================\n",
      "PER: 23.90%\n",
      "WER: 37.66%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# COMPLETE WER EVALUATION\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import editdistance\n",
    "from collections import defaultdict, Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BASE_PATH = \"/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final\"\n",
    "MODEL_PATH = \"/kaggle/input/transformer/other/default/1/best_model_full_per.pt\"\n",
    "BATCH_SIZE_VAL = 2\n",
    "NUM_WORKERS = 2\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Model architecture (must match training)\n",
    "VOCAB_SIZE = 41\n",
    "D_MODEL = 256\n",
    "NHEAD = 8\n",
    "NUM_LAYERS = 4\n",
    "DROPOUT = 0.1\n",
    "\n",
    "# Phoneme vocabulary (same as training)\n",
    "LOGIT_TO_PHONEME = [\n",
    "    \"BLANK\",  # index 0\n",
    "    \"AA\", \"AE\", \"AH\", \"AO\", \"AW\", \"AY\", \"B\", \"CH\", \"D\", \"DH\",\n",
    "    \"EH\", \"ER\", \"EY\", \"F\", \"G\", \"HH\", \"IH\", \"IY\", \"JH\", \"K\",\n",
    "    \"L\", \"M\", \"N\", \"NG\", \"OW\", \"OY\", \"P\", \"R\", \"S\", \"SH\",\n",
    "    \"T\", \"TH\", \"UH\", \"UW\", \"V\", \"W\", \"Y\", \"Z\", \"ZH\", \" | \"\n",
    "]\n",
    "idx_to_phoneme = {i: p for i, p in enumerate(LOGIT_TO_PHONEME)}\n",
    "\n",
    "# ============================================================================\n",
    "# DATA LOADING \n",
    "# ============================================================================\n",
    "\n",
    "def get_all_hdf5_files(base_path, split_name):\n",
    "    \"\"\"Recursively find all HDF5 files for a given split\"\"\"\n",
    "    all_files = []\n",
    "    for date_folder in sorted(os.listdir(base_path)):\n",
    "        if date_folder.startswith(\"t15.\"):\n",
    "            fp = os.path.join(base_path, date_folder, f\"data_{split_name}.hdf5\")\n",
    "            if os.path.exists(fp):\n",
    "                all_files.append(fp)\n",
    "    return all_files\n",
    "\n",
    "def load_full_dataset_info(h5_paths):\n",
    "    \"\"\"Load metadata from all HDF5 files\"\"\"\n",
    "    all_trials = []\n",
    "    total_trials = 0\n",
    "    \n",
    "    for h5_path in h5_paths:\n",
    "        if not os.path.exists(h5_path):\n",
    "            continue\n",
    "            \n",
    "        with h5py.File(h5_path, \"r\") as f:\n",
    "            file_trials = 0\n",
    "            for k in f.keys():\n",
    "                grp = f[k]\n",
    "                if \"seq_class_ids\" in grp:\n",
    "                    all_trials.append((h5_path, k))\n",
    "                    file_trials += 1\n",
    "            \n",
    "            print(f\"  {os.path.basename(h5_path)}: {file_trials} trials\")\n",
    "            total_trials += file_trials\n",
    "    \n",
    "    print(f\"\\nTotal trials found: {total_trials}\")\n",
    "    return all_trials\n",
    "\n",
    "class Brain2TextDatasetFull(Dataset):\n",
    "    \"\"\"Dataset loader (same as training)\"\"\"\n",
    "    def __init__(self, trial_list, max_trials=None):\n",
    "        self.trials = trial_list if max_trials is None else trial_list[:max_trials]\n",
    "        self.file_cache = {}\n",
    "        print(f\"Dataset initialized with {len(self.trials)} trials\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.trials)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_path, key = self.trials[idx]\n",
    "        \n",
    "        if file_path not in self.file_cache:\n",
    "            self.file_cache[file_path] = h5py.File(file_path, \"r\")\n",
    "        \n",
    "        f = self.file_cache[file_path]\n",
    "        grp = f[key]\n",
    "        \n",
    "        # Load neural features\n",
    "        x = grp[\"input_features\"][()]\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        \n",
    "        # Load phoneme target\n",
    "        if \"seq_class_ids\" in grp:\n",
    "            seq_class_ids = grp[\"seq_class_ids\"][()]\n",
    "            seq_len = grp.attrs.get(\"seq_len\", len(seq_class_ids))\n",
    "            phoneme_seq = seq_class_ids[:seq_len]\n",
    "            y = torch.tensor(phoneme_seq, dtype=torch.long)\n",
    "        else:\n",
    "            y = torch.tensor([], dtype=torch.long)\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __del__(self):\n",
    "        for f in self.file_cache.values():\n",
    "            try:\n",
    "                f.close()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "def ctc_collate(batch):\n",
    "    \"\"\"Collate function for CTC loss\"\"\"\n",
    "    xs, ys = zip(*batch)\n",
    "    x_lens = torch.tensor([len(x) for x in xs], dtype=torch.long)\n",
    "    y_lens = torch.tensor([len(y) for y in ys], dtype=torch.long)\n",
    "    X = nn.utils.rnn.pad_sequence(xs, batch_first=True)\n",
    "    Y = torch.cat(ys)\n",
    "    return X, Y, x_lens, y_lens\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL ARCHITECTURE (Same as training)\n",
    "# ============================================================================\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=10000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(pos * div)\n",
    "        pe[:, 1::2] = torch.cos(pos * div)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]\n",
    "\n",
    "class BrainTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size=41, d_model=256, nhead=8, num_layers=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Linear(512, d_model),\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.pos = PositionalEncoding(d_model)\n",
    "        layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dim_feedforward=d_model*4,\n",
    "            dropout=dropout, activation='gelu', batch_first=True, norm_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(layer, num_layers)\n",
    "        self.out = nn.Linear(d_model, vocab_size)\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.proj(x)\n",
    "        x = self.pos(x)\n",
    "        x = self.transformer(x, src_key_padding_mask=mask)\n",
    "        return self.out(x)\n",
    "\n",
    "# ============================================================================\n",
    "# CTC DECODING (Same as training)\n",
    "# ============================================================================\n",
    "\n",
    "def ctc_greedy_decode(logits):\n",
    "    \"\"\"CTC greedy decoding: argmax -> collapse repeats -> remove blanks\"\"\"\n",
    "    pred_ids = logits.argmax(-1).cpu().numpy()\n",
    "    decoded_sequences = []\n",
    "    \n",
    "    for seq in pred_ids:\n",
    "        collapsed = []\n",
    "        prev = -1\n",
    "        for token_id in seq:\n",
    "            if token_id != prev:\n",
    "                collapsed.append(int(token_id))\n",
    "            prev = token_id\n",
    "        no_blanks = [tok for tok in collapsed if tok != 0]\n",
    "        decoded_sequences.append(no_blanks)\n",
    "    \n",
    "    return decoded_sequences\n",
    "\n",
    "def calculate_per(predictions, ground_truths):\n",
    "    \"\"\"Calculate Phoneme Error Rate\"\"\"\n",
    "    total_edit_distance = 0\n",
    "    total_length = 0\n",
    "    \n",
    "    for pred_seq, true_seq in zip(predictions, ground_truths):\n",
    "        edit_dist = editdistance.eval(true_seq, pred_seq)\n",
    "        total_edit_distance += edit_dist\n",
    "        total_length += len(true_seq)\n",
    "    \n",
    "    per = (total_edit_distance / total_length * 100) if total_length > 0 else 100.0\n",
    "    return per, total_edit_distance, total_length\n",
    "\n",
    "# ============================================================================\n",
    "# PHONEME-TO-WORD CONVERSION\n",
    "# ============================================================================\n",
    "\n",
    "class PhonemeDictionary:\n",
    "    \"\"\"Phoneme-to-word dictionary for decoding\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Common words dictionary (phonemes as tuples -> words)\n",
    "        self.phoneme_to_words = {\n",
    "            # Pronouns\n",
    "            ('Y', 'UW'): ['you'],\n",
    "            ('HH', 'IY'): ['he'],\n",
    "            ('SH', 'IY'): ['she'],\n",
    "            ('W', 'IY'): ['we'],\n",
    "            ('DH', 'EY'): ['they'],\n",
    "            ('IH', 'T'): ['it'],\n",
    "            \n",
    "            # Common verbs\n",
    "            ('K', 'AE', 'N'): ['can'],\n",
    "            ('W', 'IH', 'L'): ['will'],\n",
    "            ('HH', 'AE', 'V'): ['have'],\n",
    "            ('W', 'AH', 'Z'): ['was'],\n",
    "            ('W', 'ER'): ['were'],\n",
    "            ('IH', 'Z'): ['is'],\n",
    "            ('S', 'IY'): ['see'],\n",
    "            ('G', 'OW'): ['go'],\n",
    "            ('K', 'AH', 'M'): ['come'],\n",
    "            ('G', 'EH', 'T'): ['get'],\n",
    "            ('M', 'EY', 'K'): ['make'],\n",
    "            ('K', 'IY', 'P'): ['keep'],\n",
    "            \n",
    "            # Articles & Prepositions\n",
    "            ('DH', 'AH'): ['the'],\n",
    "            ('AH'): ['a', 'uh'],\n",
    "            ('AE', 'N'): ['an'],\n",
    "            ('T', 'UW'): ['to', 'too'],\n",
    "            ('AH', 'V'): ['of'],\n",
    "            ('AE', 'T'): ['at'],\n",
    "            ('IH', 'N'): ['in'],\n",
    "            ('AO', 'N'): ['on'],\n",
    "            ('F', 'AO', 'R'): ['for'],\n",
    "            ('AE', 'Z'): ['as'],\n",
    "            \n",
    "            # Demonstratives\n",
    "            ('DH', 'IH', 'S'): ['this'],\n",
    "            ('DH', 'AE', 'T'): ['that'],\n",
    "            \n",
    "            # Conjunctions\n",
    "            ('AE', 'N', 'D'): ['and'],\n",
    "            ('B', 'AH', 'T'): ['but'],\n",
    "            ('AO', 'R'): ['or'],\n",
    "            \n",
    "            # Question words\n",
    "            ('HH', 'AW'): ['how'],\n",
    "            ('W', 'AH', 'T'): ['what'],\n",
    "            ('W', 'EH', 'N'): ['when'],\n",
    "            ('W', 'EH', 'R'): ['where'],\n",
    "            ('HH', 'UW'): ['who'],\n",
    "            ('W', 'AY'): ['why'],\n",
    "            \n",
    "            # Common nouns\n",
    "            ('T', 'AY', 'M'): ['time'],\n",
    "            ('P', 'IY', 'P', 'AH', 'L'): ['people'],\n",
    "            ('K', 'OW', 'D'): ['code'],\n",
    "            ('P', 'OY', 'N', 'T'): ['point'],\n",
    "            ('K', 'AA', 'S', 'T'): ['cost'],\n",
    "            ('D', 'AW', 'N'): ['down'],\n",
    "            \n",
    "            # Adjectives\n",
    "            ('N', 'UW'): ['new'],\n",
    "            ('G', 'UH', 'D'): ['good'],\n",
    "            ('N', 'AA', 'T'): ['not'],\n",
    "            \n",
    "            # Common expressions\n",
    "            ('Y', 'EH', 'S'): ['yes'],\n",
    "            ('N', 'OW'): ['no'],\n",
    "            ('W', 'EH', 'L'): ['well'],\n",
    "        }\n",
    "        \n",
    "        # Word frequencies\n",
    "        self.word_freq = Counter({\n",
    "            'the': 1000000, 'to': 500000, 'and': 450000,\n",
    "            'of': 400000, 'a': 350000, 'in': 300000,\n",
    "            'is': 250000, 'that': 200000, 'for': 180000,\n",
    "            'it': 170000, 'you': 160000, 'can': 150000,\n",
    "            'will': 140000, 'have': 130000, 'this': 120000,\n",
    "            'at': 110000, 'see': 100000, 'what': 95000,\n",
    "            'how': 90000, 'not': 85000, 'code': 50000,\n",
    "        })\n",
    "    \n",
    "    def lookup(self, phoneme_tuple):\n",
    "        \"\"\"Exact dictionary lookup\"\"\"\n",
    "        return self.phoneme_to_words.get(phoneme_tuple, None)\n",
    "    \n",
    "    def fuzzy_match(self, phoneme_tuple, max_edit_dist=2):\n",
    "        \"\"\"Find closest matches using edit distance\"\"\"\n",
    "        if not phoneme_tuple:\n",
    "            return []\n",
    "        \n",
    "        candidates = []\n",
    "        for dict_phonemes, words in self.phoneme_to_words.items():\n",
    "            dist = editdistance.eval(phoneme_tuple, dict_phonemes)\n",
    "            \n",
    "            if dist <= max_edit_dist:\n",
    "                for word in words:\n",
    "                    freq = self.word_freq.get(word, 1)\n",
    "                    score = -dist + np.log(freq) / 10\n",
    "                    candidates.append((word, score, dist))\n",
    "        \n",
    "        candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "        return candidates[:5]\n",
    "\n",
    "class PhonemeToWordConverter:\n",
    "    \"\"\"Converts phoneme sequences to word sequences\"\"\"\n",
    "    \n",
    "    def __init__(self, phoneme_dict):\n",
    "        self.phoneme_dict = phoneme_dict\n",
    "        self.silence_token = ' | '\n",
    "    \n",
    "    def convert(self, phoneme_list, use_fuzzy=True):\n",
    "        \"\"\"Convert list of phoneme strings to words\"\"\"\n",
    "        words = []\n",
    "        current_phonemes = []\n",
    "        \n",
    "        for phoneme in phoneme_list:\n",
    "            if phoneme == self.silence_token:\n",
    "                if current_phonemes:\n",
    "                    word = self._phonemes_to_word(tuple(current_phonemes), use_fuzzy)\n",
    "                    if word:\n",
    "                        words.append(word)\n",
    "                    current_phonemes = []\n",
    "            else:\n",
    "                current_phonemes.append(phoneme)\n",
    "        \n",
    "        # Handle last word\n",
    "        if current_phonemes:\n",
    "            word = self._phonemes_to_word(tuple(current_phonemes), use_fuzzy)\n",
    "            if word:\n",
    "                words.append(word)\n",
    "        \n",
    "        return words\n",
    "    \n",
    "    def _phonemes_to_word(self, phoneme_tuple, use_fuzzy=True):\n",
    "        \"\"\"Convert phoneme tuple to single word\"\"\"\n",
    "        # Exact match\n",
    "        matches = self.phoneme_dict.lookup(phoneme_tuple)\n",
    "        if matches:\n",
    "            return max(matches, key=lambda w: self.phoneme_dict.word_freq.get(w, 0))\n",
    "        \n",
    "        # Fuzzy match\n",
    "        if use_fuzzy:\n",
    "            candidates = self.phoneme_dict.fuzzy_match(phoneme_tuple)\n",
    "            if candidates:\n",
    "                return candidates[0][0]\n",
    "        \n",
    "        # Fallback\n",
    "        return '<' + '_'.join(phoneme_tuple) + '>'\n",
    "\n",
    "# ============================================================================\n",
    "# WER CALCULATION\n",
    "# ============================================================================\n",
    "\n",
    "def calculate_wer(predictions, references):\n",
    "    \"\"\"Calculate Word Error Rate\"\"\"\n",
    "    total_errors = 0\n",
    "    total_words = 0\n",
    "    \n",
    "    for pred_words, ref_words in zip(predictions, references):\n",
    "        errors = editdistance.eval(pred_words, ref_words)\n",
    "        total_errors += errors\n",
    "        total_words += len(ref_words)\n",
    "    \n",
    "    wer = (total_errors / total_words * 100) if total_words > 0 else 100.0\n",
    "    return wer, total_errors, total_words\n",
    "\n",
    "# ============================================================================\n",
    "# FULL EVALUATION FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "def evaluate_wer(model, dataloader, idx_to_phoneme, device='cuda'):\n",
    "    \"\"\"Evaluate trained model with WER metric\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    phoneme_dict = PhonemeDictionary()\n",
    "    converter = PhonemeToWordConverter(phoneme_dict)\n",
    "    \n",
    "    all_pred_phoneme_seqs = []\n",
    "    all_true_phoneme_seqs = []\n",
    "    all_pred_word_seqs = []\n",
    "    all_true_word_seqs = []\n",
    "    \n",
    "    print(\"Running evaluation...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (X, Y, x_len, y_len) in enumerate(dataloader):\n",
    "            X = X.to(device)\n",
    "            mask = torch.arange(X.size(1), device=device)[None, :] >= x_len.to(device)[:, None]\n",
    "            \n",
    "            logits = model(X, mask)\n",
    "            pred_seqs = ctc_greedy_decode(logits)\n",
    "            \n",
    "            # Convert predictions to phonemes and words\n",
    "            for pred_indices in pred_seqs:\n",
    "                pred_phonemes = [idx_to_phoneme[idx] for idx in pred_indices if idx < len(idx_to_phoneme)]\n",
    "                pred_words = converter.convert(pred_phonemes, use_fuzzy=True)\n",
    "                \n",
    "                all_pred_phoneme_seqs.append(pred_indices)\n",
    "                all_pred_word_seqs.append(pred_words)\n",
    "            \n",
    "            # Convert ground truth\n",
    "            start = 0\n",
    "            for length in y_len:\n",
    "                true_indices = Y[start:start+length].cpu().numpy().tolist()\n",
    "                true_phonemes = [idx_to_phoneme[idx] for idx in true_indices if idx < len(idx_to_phoneme)]\n",
    "                true_words = converter.convert(true_phonemes, use_fuzzy=True)\n",
    "                \n",
    "                all_true_phoneme_seqs.append(true_indices)\n",
    "                all_true_word_seqs.append(true_words)\n",
    "                start += length\n",
    "            \n",
    "            if (batch_idx + 1) % 100 == 0:\n",
    "                print(f\"  Processed {batch_idx + 1}/{len(dataloader)} batches\")\n",
    "            \n",
    "            del logits, X, mask\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    per, _, _ = calculate_per(all_pred_phoneme_seqs, all_true_phoneme_seqs)\n",
    "    wer, wer_errors, total_words = calculate_wer(all_pred_word_seqs, all_true_word_seqs)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"EVALUATION RESULTS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Phoneme Error Rate (PER): {per:.2f}%\")\n",
    "    print(f\"Word Error Rate (WER): {wer:.2f}%\")\n",
    "    print(f\"Total word errors: {wer_errors}\")\n",
    "    print(f\"Total words: {total_words}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Show samples\n",
    "    print(\"\\nSample Predictions (first 5):\")\n",
    "    for i in range(min(5, len(all_pred_phoneme_seqs))):\n",
    "        print(f\"\\n--- Sample {i+1} ---\")\n",
    "        \n",
    "        pred_phon_str = ' '.join([idx_to_phoneme[idx] for idx in all_pred_phoneme_seqs[i][:30]])\n",
    "        true_phon_str = ' '.join([idx_to_phoneme[idx] for idx in all_true_phoneme_seqs[i][:30]])\n",
    "        \n",
    "        print(f\"Pred Phonemes: {pred_phon_str}\")\n",
    "        print(f\"True Phonemes: {true_phon_str}\")\n",
    "        print(f\"Pred Words: {' '.join(all_pred_word_seqs[i])}\")\n",
    "        print(f\"True Words: {' '.join(all_true_word_seqs[i])}\")\n",
    "    \n",
    "    return {\n",
    "        'per': per,\n",
    "        'wer': wer,\n",
    "        'wer_errors': wer_errors,\n",
    "        'total_words': total_words,\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"BRAIN-TO-TEXT WER EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Load validation data\n",
    "print(\"\\nLoading validation data...\")\n",
    "val_files = get_all_hdf5_files(BASE_PATH, \"val\")\n",
    "val_trials = load_full_dataset_info(val_files)\n",
    "val_ds = Brain2TextDatasetFull(val_trials)\n",
    "val_dl = DataLoader(\n",
    "    val_ds, batch_size=BATCH_SIZE_VAL, shuffle=False,\n",
    "    collate_fn=ctc_collate, num_workers=NUM_WORKERS, pin_memory=True\n",
    ")\n",
    "\n",
    "# 2. Load trained model\n",
    "print(\"\\nLoading trained model...\")\n",
    "model = BrainTransformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    d_model=D_MODEL,\n",
    "    nhead=NHEAD,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout=DROPOUT\n",
    ")\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "print(f\"✓ Model loaded from {MODEL_PATH}\")\n",
    "print(f\"✓ Model has {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
    "\n",
    "# 3. Run evaluation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "results = evaluate_wer(\n",
    "    model=model,\n",
    "    dataloader=val_dl,\n",
    "    idx_to_phoneme=idx_to_phoneme,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"WER: {results['wer']:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67625ada",
   "metadata": {
    "papermill": {
     "duration": 0.035842,
     "end_time": "2025-11-29T14:45:42.237138",
     "exception": false,
     "start_time": "2025-11-29T14:45:42.201296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 13056355,
     "sourceId": 106809,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 518877,
     "modelInstanceId": 503803,
     "sourceId": 665621,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7375.175322,
   "end_time": "2025-11-29T14:45:45.004598",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-29T12:42:49.829276",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
