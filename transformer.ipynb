{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":106809,"databundleVersionId":13056355,"sourceType":"competition"}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!ls -R /kaggle/input/brain-to-text-25\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-25T11:10:11.092298Z","iopub.execute_input":"2025-11-25T11:10:11.092621Z","iopub.status.idle":"2025-11-25T11:10:11.607475Z","shell.execute_reply.started":"2025-11-25T11:10:11.092586Z","shell.execute_reply":"2025-11-25T11:10:11.606821Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/brain-to-text-25:\ndata_link.txt  t15_copyTask_neuralData\tt15_pretrained_rnn_baseline\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData:\nhdf5_data_final\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final:\nt15.2023.08.11\tt15.2023.09.29\tt15.2023.11.04\tt15.2024.02.25\tt15.2024.07.19\nt15.2023.08.13\tt15.2023.10.01\tt15.2023.11.17\tt15.2024.03.03\tt15.2024.07.21\nt15.2023.08.18\tt15.2023.10.06\tt15.2023.11.19\tt15.2024.03.08\tt15.2024.07.28\nt15.2023.08.20\tt15.2023.10.08\tt15.2023.11.26\tt15.2024.03.15\tt15.2025.01.10\nt15.2023.08.25\tt15.2023.10.13\tt15.2023.12.03\tt15.2024.03.17\tt15.2025.01.12\nt15.2023.08.27\tt15.2023.10.15\tt15.2023.12.08\tt15.2024.04.25\tt15.2025.03.14\nt15.2023.09.01\tt15.2023.10.20\tt15.2023.12.10\tt15.2024.04.28\tt15.2025.03.16\nt15.2023.09.03\tt15.2023.10.22\tt15.2023.12.17\tt15.2024.05.10\tt15.2025.03.30\nt15.2023.09.24\tt15.2023.11.03\tt15.2023.12.29\tt15.2024.06.14\tt15.2025.04.13\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.11:\ndata_train.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.13:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.18:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.20:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.25:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.27:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.09.01:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.09.03:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.09.24:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.09.29:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.01:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.06:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.08:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.13:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.15:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.20:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.22:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.03:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.04:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.17:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.19:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.26:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.03:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.08:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.10:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.17:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.29:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.02.25:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.03.03:\ndata_train.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.03.08:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.03.15:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.03.17:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.04.25:\ndata_train.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.04.28:\ndata_train.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.05.10:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.06.14:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.07.19:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.07.21:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.07.28:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.01.10:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.01.12:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.03.14:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.03.16:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.03.30:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.04.13:\ndata_test.hdf5\tdata_train.hdf5  data_val.hdf5\n\n/kaggle/input/brain-to-text-25/t15_pretrained_rnn_baseline:\nt15_pretrained_rnn_baseline\n\n/kaggle/input/brain-to-text-25/t15_pretrained_rnn_baseline/t15_pretrained_rnn_baseline:\ncheckpoint  training_log\n\n/kaggle/input/brain-to-text-25/t15_pretrained_rnn_baseline/t15_pretrained_rnn_baseline/checkpoint:\nargs.yaml  best_checkpoint\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import h5py\n\nsample = \"/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.01.12/data_train.hdf5\"\nwith h5py.File(sample, \"r\") as f:\n    first_trial = list(f.keys())[0]\n    print(\"Example trial:\", first_trial)\n    print(\"Contents:\")\n    for key in f[first_trial].keys():\n        print(\"  \", key)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T11:10:11.608852Z","iopub.execute_input":"2025-11-25T11:10:11.609099Z","iopub.status.idle":"2025-11-25T11:10:12.064723Z","shell.execute_reply.started":"2025-11-25T11:10:11.609075Z","shell.execute_reply":"2025-11-25T11:10:12.063956Z"}},"outputs":[{"name":"stdout","text":"Example trial: trial_0000\nContents:\n   input_features\n   seq_class_ids\n   transcription\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"train_h5 = \"/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.01.12/data_train.hdf5\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T11:10:12.066206Z","iopub.execute_input":"2025-11-25T11:10:12.066626Z","iopub.status.idle":"2025-11-25T11:10:12.070075Z","shell.execute_reply.started":"2025-11-25T11:10:12.066606Z","shell.execute_reply":"2025-11-25T11:10:12.069348Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Extract all label IDs from train set to infer vocabulary\nall_ids = set()\n\nwith h5py.File(train_h5, \"r\") as f:\n    for k in list(f.keys())[:200]:   # first 200 trials are enough\n        ids = f[f\"{k}/seq_class_ids\"][:]\n        all_ids.update(ids.tolist())\n\nprint(\"Unique token IDs:\", sorted(all_ids))\nprint(\"Count:\", len(all_ids))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T11:10:12.071571Z","iopub.execute_input":"2025-11-25T11:10:12.071788Z","iopub.status.idle":"2025-11-25T11:10:13.162781Z","shell.execute_reply.started":"2025-11-25T11:10:12.071770Z","shell.execute_reply":"2025-11-25T11:10:13.162115Z"}},"outputs":[{"name":"stdout","text":"Unique token IDs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\nCount: 41\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import h5py, numpy as np, torch, torch.nn as nn, torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport math, random\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", DEVICE)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T11:10:13.163559Z","iopub.execute_input":"2025-11-25T11:10:13.163824Z","iopub.status.idle":"2025-11-25T11:10:19.131344Z","shell.execute_reply.started":"2025-11-25T11:10:13.163800Z","shell.execute_reply":"2025-11-25T11:10:19.130515Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# ASCII printable characters + mandatory blank at index 0\nchars = ['<blank>'] + [chr(i) for i in range(32,127)]\nstoi = {c:i for i,c in enumerate(chars)}\nitos = {i:c for c,i in stoi.items()}\nVOCAB_SIZE = len(stoi)\n\ndef ascii_to_tokens(arr):\n    # Converts raw ascii ints → model token ids\n    out=[]\n    for x in arr:\n        if x == 0: \n            continue\n        c = chr(int(x))\n        if c in stoi:\n            out.append(stoi[c])\n    return torch.tensor(out, dtype=torch.long)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T11:10:19.132230Z","iopub.execute_input":"2025-11-25T11:10:19.132551Z","iopub.status.idle":"2025-11-25T11:10:19.137799Z","shell.execute_reply.started":"2025-11-25T11:10:19.132533Z","shell.execute_reply":"2025-11-25T11:10:19.137235Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"class Brain2TextDataset(Dataset):\n    def __init__(self, h5_path, max_trials=None):\n        self.f = h5py.File(h5_path, \"r\")\n        keys = list(self.f.keys())\n\n        # Keep only trials that contain *at least one* label source\n        self.valid_keys = []\n        for k in keys:\n            grp = self.f[k]\n            if \"transcription\" in grp or \"seq_class_ids\" in grp:\n                self.valid_keys.append(k)\n\n        if max_trials is not None:\n            self.valid_keys = self.valid_keys[:max_trials]\n\n    def __len__(self):\n        return len(self.valid_keys)\n\n    def __getitem__(self, idx):\n        k = self.valid_keys[idx]\n        grp = self.f[k]\n\n        # Neural data\n        x = grp[\"input_features\"][()]  # (T, 512)\n\n        # Labels: use transcription first, else fallback\n        if \"transcription\" in grp:\n            y_raw = grp[\"transcription\"][()]  # ASCII ints\n            y = ascii_to_tokens(y_raw)\n\n        else:\n            # seq_class_ids are already integers (but may include 0 padding)\n            y_raw = grp[\"seq_class_ids\"][()]\n            y = torch.tensor([t for t in y_raw if t != 0], dtype=torch.long)\n\n        return torch.tensor(x, dtype=torch.float32), y\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T11:10:19.138441Z","iopub.execute_input":"2025-11-25T11:10:19.138617Z","iopub.status.idle":"2025-11-25T11:10:19.158501Z","shell.execute_reply.started":"2025-11-25T11:10:19.138603Z","shell.execute_reply":"2025-11-25T11:10:19.158067Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T11:10:19.159196Z","iopub.execute_input":"2025-11-25T11:10:19.159810Z","iopub.status.idle":"2025-11-25T11:10:19.180346Z","shell.execute_reply.started":"2025-11-25T11:10:19.159787Z","shell.execute_reply":"2025-11-25T11:10:19.179665Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def ctc_collate(batch):\n    xs, ys = zip(*batch)  # lists of tensors\n    x_lens = torch.tensor([len(x) for x in xs], dtype=torch.long)\n    y_lens = torch.tensor([len(y) for y in ys], dtype=torch.long)\n\n    X = nn.utils.rnn.pad_sequence(xs, batch_first=True)\n    Y = torch.cat(ys)\n\n    return X, Y, x_lens, y_lens\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T11:10:19.181029Z","iopub.execute_input":"2025-11-25T11:10:19.181247Z","iopub.status.idle":"2025-11-25T11:10:19.197410Z","shell.execute_reply.started":"2025-11-25T11:10:19.181216Z","shell.execute_reply":"2025-11-25T11:10:19.196885Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# train_h5 = \"/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.01.12/data_train.hdf5\"\n# val_h5   = \"/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.01.12/data_val.hdf5\"\n# test_h5  = \"/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.01.12/data_test.hdf5\"\n\n# train_ds = Brain2TextDataset(train_h5, max_trials=800)   # adjust subset size\n# val_ds   = Brain2TextDataset(val_h5, max_trials=200)\n# test_ds  = Brain2TextDataset(test_h5, max_trials=200)\n\n# train_dl = DataLoader(train_ds, batch_size=8, shuffle=True, collate_fn=ctc_collate)\n# val_dl   = DataLoader(val_ds, batch_size=8, shuffle=False, collate_fn=ctc_collate)\n# test_dl  = DataLoader(test_ds, batch_size=8, shuffle=False, collate_fn=ctc_collate)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T11:10:19.199373Z","iopub.execute_input":"2025-11-25T11:10:19.199794Z","iopub.status.idle":"2025-11-25T11:10:20.201696Z","shell.execute_reply.started":"2025-11-25T11:10:19.199778Z","shell.execute_reply":"2025-11-25T11:10:20.201066Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"BASE = \"/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.01.12\"\n\ntrain_h5 = f\"{BASE}/data_train.hdf5\"\nval_h5   = f\"{BASE}/data_val.hdf5\"\ntest_h5  = f\"{BASE}/data_test.hdf5\"\n\nprint(train_h5)\nprint(val_h5)\nprint(test_h5)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_ds = Brain2TextDataset(train_h5, max_trials=3000)\nval_ds   = Brain2TextDataset(val_h5,   max_trials=500)\ntest_ds  = Brain2TextDataset(test_h5,  max_trials=500)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TransformerBlock(nn.Module):\n    def __init__(self, dim, heads=4, mlp_ratio=4.0, dropout=0.1):\n        super().__init__()\n        self.attn = nn.MultiheadAttention(dim, heads, dropout=dropout, batch_first=True)\n        self.ln1 = nn.LayerNorm(dim)\n\n        self.mlp = nn.Sequential(\n            nn.Linear(dim, int(dim * mlp_ratio)),\n            nn.GELU(),\n            nn.Linear(int(dim * mlp_ratio), dim),\n        )\n        self.ln2 = nn.LayerNorm(dim)\n\n    def forward(self, x):\n        attn_out, _ = self.attn(x, x, x)\n        x = self.ln1(x + attn_out)\n        x = self.ln2(x + self.mlp(x))\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T11:10:20.202409Z","iopub.execute_input":"2025-11-25T11:10:20.202614Z","iopub.status.idle":"2025-11-25T11:10:20.207957Z","shell.execute_reply.started":"2025-11-25T11:10:20.202598Z","shell.execute_reply":"2025-11-25T11:10:20.207232Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"class CNNTransformerCTC(nn.Module):\n    def __init__(self, feat_dim=512, model_dim=256, num_layers=4, vocab_size=VOCAB_SIZE):\n        super().__init__()\n\n        # 1D CNN for smoothing + local features\n        self.conv = nn.Sequential(\n            nn.Conv1d(feat_dim, model_dim, kernel_size=5, padding=2),\n            nn.GELU(),\n            nn.Conv1d(model_dim, model_dim, kernel_size=5, padding=2),\n            nn.GELU(),\n        )\n\n        # transformer layers\n        self.layers = nn.ModuleList([\n            TransformerBlock(model_dim, heads=4, mlp_ratio=4.0, dropout=0.1)\n\n            for _ in range(num_layers)\n        ])\n\n        # output classifier\n        self.fc = nn.Linear(model_dim, vocab_size)\n\n    def forward(self, x, x_lens):\n        # (B, T, C) → (B, C, T)\n        x = x.transpose(1, 2)\n        x = self.conv(x)\n        x = x.transpose(1, 2)\n\n        for layer in self.layers:\n            x = layer(x)\n\n        logits = self.fc(x)\n        return F.log_softmax(logits, dim=-1), x_lens\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T11:10:20.208765Z","iopub.execute_input":"2025-11-25T11:10:20.209005Z","iopub.status.idle":"2025-11-25T11:10:20.227906Z","shell.execute_reply.started":"2025-11-25T11:10:20.208983Z","shell.execute_reply":"2025-11-25T11:10:20.227249Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"class EarlyStopping:\n    def __init__(self, patience=5, min_delta=0.0):\n        self.patience = patience\n        self.min_delta = min_delta\n        self.best_wer = float(\"inf\")\n        self.counter = 0\n        self.should_stop = False\n\n    def step(self, current_wer):\n        if current_wer < self.best_wer - self.min_delta:\n            self.best_wer = current_wer\n            self.counter = 0\n        else:\n            self.counter += 1\n\n        if self.counter >= self.patience:\n            self.should_stop = True\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T11:10:20.228673Z","iopub.execute_input":"2025-11-25T11:10:20.229190Z","iopub.status.idle":"2025-11-25T11:10:20.251197Z","shell.execute_reply.started":"2025-11-25T11:10:20.229165Z","shell.execute_reply":"2025-11-25T11:10:20.250648Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"model = CNNTransformerCTC().to(DEVICE)\nctc_loss = nn.CTCLoss(blank=0, zero_infinity=True)\noptimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.01)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T11:10:20.251889Z","iopub.execute_input":"2025-11-25T11:10:20.252151Z","iopub.status.idle":"2025-11-25T11:10:23.744075Z","shell.execute_reply.started":"2025-11-25T11:10:20.252127Z","shell.execute_reply":"2025-11-25T11:10:23.743490Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def train_step(dataloader):\n    model.train()\n    total_loss = 0\n\n    for X, Y, x_lens, y_lens in dataloader:\n        X = X.to(DEVICE)\n        Y = Y.to(DEVICE)\n        x_lens = x_lens.to(DEVICE)\n        y_lens = y_lens.to(DEVICE)\n\n        optimizer.zero_grad()\n        logp, out_lens = model(X, x_lens)\n\n        loss = ctc_loss(\n            logp.transpose(0,1),\n            Y,\n            out_lens,\n            y_lens\n        )\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    return total_loss / len(dataloader)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T11:10:23.744730Z","iopub.execute_input":"2025-11-25T11:10:23.745069Z","iopub.status.idle":"2025-11-25T11:10:23.749901Z","shell.execute_reply.started":"2025-11-25T11:10:23.745026Z","shell.execute_reply":"2025-11-25T11:10:23.749201Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def edit_distance(a, b):\n    dp = [[0]*(len(b)+1) for _ in range(len(a)+1)]\n    for i in range(len(a)+1): dp[i][0] = i\n    for j in range(len(b)+1): dp[0][j] = j\n\n    for i in range(1, len(a)+1):\n        for j in range(1, len(b)+1):\n            cost = 0 if a[i-1] == b[j-1] else 1\n            dp[i][j] = min(\n                dp[i-1][j] + 1,\n                dp[i][j-1] + 1,\n                dp[i-1][j-1] + cost\n            )\n    return dp[-1][-1]\n\n\ndef greedy_decode(logp, lens):\n    pred = logp.argmax(dim=-1)\n    results = []\n    for i in range(pred.size(0)):\n        seq = pred[i][:lens[i]].tolist()\n        cleaned = []\n        last = None\n        for x in seq:\n            if x != 0 and x != last:\n                cleaned.append(x)\n            last = x\n        results.append(cleaned)\n    return results\n\n\ndef validate(dataloader):\n    model.eval()\n    total = 0\n    count = 0\n\n    with torch.no_grad():\n        for X, Y, x_lens, y_lens in dataloader:\n            X = X.to(DEVICE)\n            x_lens = x_lens.to(DEVICE)\n\n            logp, out_lens = model(X, x_lens)\n\n            preds = greedy_decode(logp.cpu(), out_lens.cpu())\n\n            # split Y according to y_lens\n            idx = 0\n            targets = []\n            for L in y_lens:\n                targets.append(Y[idx:idx+L].tolist())\n                idx += L\n\n            for p, t in zip(preds, targets):\n                if len(t) == 0:\n                    continue\n                total += edit_distance(p, t) / len(t)\n                count += 1\n\n    return total / count\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T11:10:23.750618Z","iopub.execute_input":"2025-11-25T11:10:23.750894Z","iopub.status.idle":"2025-11-25T11:10:23.779550Z","shell.execute_reply.started":"2025-11-25T11:10:23.750877Z","shell.execute_reply":"2025-11-25T11:10:23.779084Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"early_stop = EarlyStopping(patience=8)\nmin_epochs = 10\n\nfor epoch in range(1, 60):\n    tr = train_step(train_dl)\n    val = validate(val_dl)\n\n    print(f\"Epoch {epoch:02d} | Train {tr:.3f} | Val WER {val:.3f}\")\n\n    if epoch > min_epochs:\n        early_stop.step(val)\n        if early_stop.should_stop:\n            print(f\"Stopped at epoch {epoch}, best WER={early_stop.best_wer:.3f}\")\n            break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T11:10:23.780166Z","iopub.execute_input":"2025-11-25T11:10:23.780373Z","iopub.status.idle":"2025-11-25T11:14:33.738277Z","shell.execute_reply.started":"2025-11-25T11:10:23.780354Z","shell.execute_reply":"2025-11-25T11:14:33.737451Z"}},"outputs":[{"name":"stdout","text":"Epoch 01 | Train 12.875 | Val WER 1.000\nEpoch 02 | Train 3.243 | Val WER 1.000\nEpoch 03 | Train 3.154 | Val WER 1.000\nEpoch 04 | Train 3.101 | Val WER 1.000\nEpoch 05 | Train 3.015 | Val WER 1.000\nEpoch 06 | Train 2.828 | Val WER 1.000\nEpoch 07 | Train 2.543 | Val WER 1.000\nEpoch 08 | Train 2.280 | Val WER 1.000\nEpoch 09 | Train 2.040 | Val WER 1.000\nEpoch 10 | Train 1.794 | Val WER 0.999\nEpoch 11 | Train 1.537 | Val WER 0.995\nEpoch 12 | Train 1.293 | Val WER 0.958\nEpoch 13 | Train 1.051 | Val WER 0.916\nEpoch 14 | Train 0.804 | Val WER 0.805\nEpoch 15 | Train 0.600 | Val WER 0.808\nEpoch 16 | Train 0.464 | Val WER 0.847\nEpoch 17 | Train 0.361 | Val WER 0.790\nEpoch 18 | Train 0.284 | Val WER 0.770\nEpoch 19 | Train 0.253 | Val WER 0.772\nEpoch 20 | Train 0.235 | Val WER 0.744\nEpoch 21 | Train 0.215 | Val WER 0.773\nEpoch 22 | Train 0.206 | Val WER 0.717\nEpoch 23 | Train 0.166 | Val WER 0.722\nEpoch 24 | Train 0.139 | Val WER 0.701\nEpoch 25 | Train 0.128 | Val WER 0.688\nEpoch 26 | Train 0.092 | Val WER 0.706\nEpoch 27 | Train 0.080 | Val WER 0.685\nEpoch 28 | Train 0.066 | Val WER 0.695\nEpoch 29 | Train 0.065 | Val WER 0.704\nEpoch 30 | Train 0.062 | Val WER 0.698\nEpoch 31 | Train 0.043 | Val WER 0.694\nEpoch 32 | Train 0.041 | Val WER 0.702\nEpoch 33 | Train 0.035 | Val WER 0.698\nEpoch 34 | Train 0.025 | Val WER 0.717\nEpoch 35 | Train 0.027 | Val WER 0.716\nStopped at epoch 35, best WER=0.685\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}